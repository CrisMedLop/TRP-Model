# -*- coding: utf-8 -*-
"""TRP100.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p6YvWGAG1AjQ9N6MbS1zh_FN8A76LQkB
"""

import numpy as np
from scipy.special import  gammainc, gammaln
from scipy.optimize import minimize
import matplotlib.pyplot as plt
from scipy.stats import gamma as gamma_dist
from scipy.integrate import quad


############################################################
# Variables globales ################## ####################
############################################################

Lim_fallas = 50
aparam = 0.2
bparam =1.5
beta= 2

############################################################

def tiempo_censura_trans (lim_inf, lim_sup, rng):
  """
  Función para obtener el tiempo de censura en el dominio transformado,
  el cual se proviene de una distribución U(15, 20).
  """
  if rng is None:
      rng = np.random.default_rng()
  t_censura_tr = rng.uniform(lim_inf, lim_sup)
  return(t_censura_tr)

def CFCP_trans ( t_censura_tr, rng):
  """
  Función para obtener el Proceso de Conteo de Fallas Completo (CFCP)
  en el dominio transformado, este se comporta como un Proceso de Renovación (RP),
  cuya distribución de renovación es una Gamma(2, 0.2).
  """
  if rng is None:
        rng = np.random.default_rng()

  tiempos_tr = []
  S = 0.0  # tiempo en dominio transformado
  for _ in range(Lim_fallas):
        # siguiente incremento en transformado
        S += rng.gamma(shape=beta, scale=1/beta)
        if S > t_censura_tr:
            break
        tiempos_tr.append(S)

  return np.array(tiempos_tr, dtype=float)

def tiempo_censura_ori (t_censura_tr):
  """
  Se obtiene el tiempo de censura en el dominio de tiempo original, para ello se
  aplica la transformación temporal inversa $\Lambda ^{-1}(t)= (t/a)^{1/b}$
  """
  exponente = 1.0 / bparam
  t_censura_ori = (t_censura_tr/aparam)**exponente
  return (t_censura_ori)

def CFCP_ori (tiempos_tr):
  """
  Función para obtener el Proceso de Conteo de Fallas Completo (CFCP)
  en el dominio de tiempo original, para ello se aplica la transformación
  temporal inversa a cada uno de los elementos del CFCP en el dominio transformado.
  """
  elementos = len(tiempos_tr)
  tiempos_ori = [0]*elementos
  for i in range (elementos):
        exponente = 1.0 / bparam
        tiempos_ori[i]= (tiempos_tr[i]/aparam)**exponente
  return np.array(tiempos_ori, dtype=float)


############################################################

def IFCP (porcentaje_perdido, arreglo, rng):
    """
    Utiliza el arreglo del CFCP y el porcentaje de perdida para generar
    el Proceso de Conteo de Fallas Incompleto (IFCP), se obtiene así
    un arreglo bidimensional correspondiente a {(T_i, k_i), i=1,...,n}
    """
    if rng is None:
        rng = np.random.default_rng()

    arr = np.asarray(arreglo, dtype=float)
    n = arr.size
    n_obs = int(round((100 - porcentaje_perdido) * n / 100.0))
    n_obs = max(0, min(n_obs, n))

    # índices 1..n (convención 1-based)
    idx_all = np.arange(1, n + 1)
    if n_obs > 0:
        idx_obs = np.sort(rng.choice(idx_all, size=n_obs, replace=False))
        T_obs = arr[idx_obs - 1]
        sample = np.column_stack([T_obs, idx_obs])
    else:
        sample = np.empty((0, 2), dtype=float)

    return sample

##############################################################

def Presentation (Tiempos_de_falla, Data, tiempocensura):
  """
  En esta función se realiza una gráfica y se muestran los datos observados y perdidos.
  """
  num_fallas = len(Tiempos_de_falla)
  num_obs = len(Data)


  indices_vistos = [0]*num_obs

  for i in range(num_obs):
        indices_vistos[i] = Data[i][1]


  tiempos = np.array(Tiempos_de_falla)

    # Creamos listas separadas para observados y perdidos
  x_obs = []
  y_obs = []
  x_perd = []
  y_perd = []

  for i in range(num_fallas):
        if (i+1) not in indices_vistos:
            x_perd.append(i +1)  # +1 para que el conteo empiece en 1
            y_perd.append(tiempos[i])
        else:
            x_obs.append(i +1)
            y_obs.append(tiempos[i])

    # Graficar
  plt.figure(figsize=(8, 5))
  plt.scatter(x_obs, y_obs, marker='o', facecolors='black', edgecolors='black', label='Observado')   # círculo sólido
  plt.scatter(x_perd, y_perd, marker='o', facecolors='none', edgecolors='red', label='Perdido')      # círculo vacío

  plt.axhline(y=tiempocensura, linestyle='--', linewidth=1.5, color='navy', label='Censura (tau)')

  plt.xlabel('Número de falla en la lista')
  plt.ylabel('Tiempo de falla')
  plt.title('Fallas observadas y perdidas')
  plt.legend()
  plt.grid(True)
  plt.show()

  print("-------REVISIÓN DE DATOS-----------")
  print("El tiempo de censura es:",  f"{tiempocensura:.3f}")
  print("el número total de fallas es: ", num_fallas, " pero el número de fallas observado es: ",num_obs )
  print("Los tiempos e indices de los datos observados son: ")
  for i in range(num_obs):
        print("tiempo de falla: ", f"{Data[i][0]:.3f}", " corresponde a la falla número: ", f"{Data[i][1]:.0f}" )
  return ()

##############################################################
"""
En este bloque de código se simulan el tiempo de censura y CFCP en el dominio de tiempo
transformado, se convierte al tiempo original y se genera el IFCP.
"""

tau_tr = tiempo_censura_trans(15, 20, None)
Tiempos_falla_tr = CFCP_trans(tau_tr,None)

tau = tiempo_censura_ori(tau_tr)
Tiempos_de_falla = CFCP_ori(Tiempos_falla_tr)

"El porcentaje de datos perdidos se ingresa manualmente"
T = IFCP(20, Tiempos_de_falla, None)

"Se definen algunas variables a utilizar para la estimación"
num_obs = len(T)
num_fallas = len(Tiempos_de_falla)

"Se presentan los datos"
Presentation(Tiempos_de_falla, T, tau)

############################################################
# FUNCIÓN DE LOG VEROSIMILITUD CASO 1 ######################
############################################################

def logverosimilitud_1(params):
    """
    Caso 1: el último tiempo observado es la última falla antes de la censura.
    """
    a, b, beta = params

    # Dominio de parámetros
    if a <= 0 or b <= 0 or beta <= 0:
        return -np.inf

    n = num_obs
    if n <= 0:
        return -np.inf

    suma = 0.0

    for i in range(n):
        t = float(T[i][0])

        if i == 0:
            delta_k = float(T[i][1])
            # Termino i=0 (usa t**b)
            suma += (
                -gammaln(beta * delta_k)
                + beta * delta_k * (np.log(a) + np.log(beta))
                + (beta * delta_k - 1.0) * b*np.log(t)
                - beta * a * (t**b)
                + (b - 1.0) * np.log(t)
            )
        else:
            delta_k = float(T[i][1] - T[i-1][1])
            tb = float(T[i-1][0])
            diff = t**b - tb**b
            if diff <= 0:   # robustez numérica
                return -np.inf
            suma += (
                -gammaln(beta * delta_k)
                + beta * delta_k * (np.log(a) + np.log(beta))
                + (beta * delta_k - 1.0) * np.log(diff)
                - beta * a * diff
                + (b - 1.0) * np.log(t)
            )

    # Último observado antes de la censura
    T_n = float(T[n-1][0])

    # Término de confiabilidad (k_tau - k_n = 0)
    upper_limit = beta * a * (tau**b - T_n**b)
    # Estabilizar: no permitir x<0 y acotar a (1e-15, 1-1e-15)
    integral_term = gammainc(beta, max(0.0, upper_limit))
    integral_term = min(max(integral_term, 1e-15), 1.0 - 1e-15)

    last_term = n * np.log(b) + np.log1p(-integral_term)

    return suma + last_term

############################################################
# FUNCIÓN DE LOG VEROSIMILITUD CASO 2 ######################
############################################################

def logverosimilitud_2(params):
    """
    Caso 2: el último tiempo observado NO es la última falla antes de la censura.
    Usa:
      - T:       array Nx2 con (t_i, k_i)
      - tau:     tiempo de censura (original)
      - num_fallas: total de fallas
      - num_obs: número de observaciones
    Requiere: a>0, b>0, beta>0.
    """
    a, b, beta = params

    # Dominio de parámetros
    if not (a > 0 and b > 0 and beta > 0):
        return -np.inf

    n = num_obs
    if n <= 0:
        return -np.inf

    # Suma de términos de verosimilitud (parte de densidades/likelihood por observaciones)
    suma = 0.0
    for i in range(n):
        t = float(T[i][0])
        if t <= 0:
            return -np.inf

        if i == 0:
            delta_k = float(T[i][1])
            # término i=0; preferimos b*log(t) por estabilidad
            suma += (
                -gammaln(beta * delta_k)
                + beta * delta_k * (np.log(a) + np.log(beta))
                + (beta * delta_k - 1.0) * (b * np.log(t))
                - beta * a * (t**b)
                + (b - 1.0) * np.log(t)
            )
        else:
            delta_k = float(T[i][1] - T[i-1][1])
            if delta_k <= 0:
                return -np.inf
            tb = float(T[i-1][0])
            if tb <= 0 or t <= tb:
                return -np.inf
            diff = t**b - tb**b
            if diff <= 0:
                return -np.inf
            suma += (
                -gammaln(beta * delta_k)
                + beta * delta_k * (np.log(a) + np.log(beta))
                + (beta * delta_k - 1.0) * np.log(diff)
                - beta * a * diff
                + (b - 1.0) * np.log(t)
            )

    # Parámetros para el término de censura con Delta>0 fallas no observadas
    T_n = float(T[n - 1][0])
    k_n = int(T[n - 1][1])
    Delta = int(num_fallas - k_n)   # número de fallas no observadas
    if Delta <= 0:
        return -np.inf

    # A = a*(tau^b - T_n^b) debe ser > 0
    A = a * (tau**b - T_n**b)
    if not np.isfinite(A) or A <= 0:
        return -np.inf

    # integral_1 = P(shape, upper), con shape=beta*Delta, upper=beta*A
    shape = beta * Delta
    upper = beta * A
    # Si por redondeo shape<=0 o upper<=0, penaliza
    if shape <= 0 or upper <= 0:
        return -np.inf

    # Recorte para estabilidad
    eps = 1e-15
    integral_1 = gammainc(shape, upper)
    integral_1 = float(np.clip(integral_1, eps, 1.0 - eps))

    # integral_2 = ∫_0^A Gamma(shape,1/beta).pdf(x) * P(beta, beta*(A - x)) dx
    # Lo calculamos con quad y un integrando estable (log-espacio).
    def outer_integrand(x):
        # x ∈ [0, A]
        inner_upper = beta * (A - x)
        if inner_upper <= 0:
            return 0.0
        inner = gammainc(beta, inner_upper)  # ∈ (0,1)
        if inner <= 0.0:
            return 0.0
        # densidad Gamma(shape, scale=1/beta)
        logdens = gamma_dist.logpdf(x, a=shape, loc=0.0, scale=1.0 / beta)
        if not np.isfinite(logdens):
            return 0.0
        # integrando en log-espacio
        val = np.exp(logdens + np.log(inner))
        return float(val) if np.isfinite(val) else 0.0

    outer_upper = A
    if outer_upper <= 0:
        integral_2 = 0.0
    else:
        result, _ = quad(outer_integrand, 0.0, outer_upper, limit=80)
        integral_2 = float(result) if np.isfinite(result) else 0.0

    # Diferencia (debe ser positiva)
    diferencia = integral_1 - integral_2
    tiny = 1e-300
    if not np.isfinite(diferencia) or diferencia <= 0:
        return -np.inf

    last_term = n * np.log(b) + np.log(max(diferencia, tiny))
    return suma + last_term

############################################################
# VERSIÓN NEGATIVA DE LAS FUNCIONES ########################
############################################################

#Cuidar valor menos infinito

def safe_neg(fun, params):
    val = fun(params)
    if not np.isfinite(val):
        return 1e50
    return -val


###########################################################

def neg_logverosimilitud_1(params):
    return safe_neg(logverosimilitud_1, params)

def neg_logverosimilitud_2(params):
    return safe_neg(logverosimilitud_2, params)


############################################################
# Estimaciones #############################################
############################################################


# Estimación inicial y restricciones (a, b, beta > 0)
x0 = [
    np.random.uniform(0.1, 2.0),  # a
    np.random.uniform(0.1, 2.0),  # b
    np.random.uniform(0.5, 6.0)   # beta
]
bounds = [(1e-5, None)] * 3

Diferencia_final = num_fallas - T[num_obs-1][1]

print("\n El número total de fallas fue: ", num_fallas, ", el índice de la última falla observada es: ", T[num_obs-1][1])

if Diferencia_final == 0:
    print("\n Caso 1: Función de confiabilidad R1")
    res = minimize(neg_logverosimilitud_1 , x0, method='Nelder-Mead', bounds=bounds)

# Resultados
    if res.success:
        print("Resultado de optimización:")
        print(f"a = {res.x[0]:.6f}")
        print(f"b = {res.x[1]:.6f}")
        print(f"beta = {res.x[2]:.6f}")
        print(f"Valor máximo aproximado: {-res.fun:.6f}")
        print("Valor de la función en la aproximación inicial", logverosimilitud_1(x0))
    else:
        print("La optimización no fue exitosa.")
        print("Mensaje:", res.message)

elif Diferencia_final > 0:
    print("\n Caso 2: Función de confiabilidad R2")
    res = minimize(neg_logverosimilitud_2 , x0, method='Nelder-Mead', bounds=bounds)

# Resultados
    if res.success:
        print("Resultado de optimización:")
        print(f"a = {res.x[0]:.6f}")
        print(f"b = {res.x[1]:.6f}")
        print(f"beta = {res.x[2]:.6f}")
        print(f"Valor máximo aproximado: {-res.fun:.6f}")
        print("Valor de la función en la aproximación inicial", logverosimilitud_2(x0))
    else:
        print("La optimización no fue exitosa.")
        print("Mensaje:", res.message)

#########################################################
#########################################################


Iteraciones = 10
exito = 0
fracaso = 0
a_prom = 0
b_prom = 0
beta_prom = 0
sin_cambios = 0



for j in range (Iteraciones):
    tau_tr = tiempo_censura_trans(15, 20, None)
    Tiempos_falla_tr = CFCP_trans(tau_tr,None)

    tau = tiempo_censura_ori(tau_tr)
    Tiempos_de_falla = CFCP_ori(Tiempos_falla_tr)
    T = IFCP(20, Tiempos_de_falla, None)
    num_obs = len(T)
    num_fallas = len(Tiempos_de_falla)
    print("%%%%%%%%%%%%%%%%%%%%%% ITERACIÓN ", j,"%%%%%%%%%%%%%%%%%%%%%%%%%%%" )
    #Revisar_Datos(tau, num_fallas, num_obs, T)

    x0 = [
        np.random.uniform(0.1, 2.0),  # a
        np.random.uniform(0.1, 2.0),  # b
        np.random.uniform(0.5, 6.0)   # beta
    ]
    bounds = [(1e-5, None)] * 3

    Diferencia_final = num_fallas - T[num_obs-1][1]

    print("\n El número total de fallas fue: ", num_fallas, ", el índice de la última falla observada es: ", T[num_obs-1][1])

    if Diferencia_final == 0:
        print("\n Caso 1: Función de confiabilidad R1")
        res = minimize(neg_logverosimilitud_1 , x0, method='Nelder-Mead', bounds=bounds)

    # Resultados
        if res.success:
            print("Resultado de optimización:")
            print(f"a = {res.x[0]:.6f}")
            print(f"b = {res.x[1]:.6f}")
            print(f"beta = {res.x[2]:.6f}")
            print(f"Valor máximo aproximado: {-res.fun:.6f}")
            print("Valor de la función en la aproximación inicial", logverosimilitud_1(x0))
            exito += 1
            a_prom = res.x[0] + a_prom
            b_prom = res.x[1] + b_prom
            beta_prom = res.x[2] + beta_prom
            print(x0)
            if (logverosimilitud_1(x0)== -res.fun):
                sin_cambios += 1
        else:
            print("La optimización no fue exitosa.")
            print("Mensaje:", res.message)
            fracaso += 1

    elif Diferencia_final > 0:
        print("\n Caso 2: Función de confiabilidad R2")
        res = minimize(neg_logverosimilitud_2 , x0, method='Nelder-Mead', bounds=bounds)

    # Resultados
        if res.success:
            print("Resultado de optimización:")
            print(f"a = {res.x[0]:.6f}")
            print(f"b = {res.x[1]:.6f}")
            print(f"beta = {res.x[2]:.6f}")
            print(f"Valor máximo aproximado: {-res.fun:.6f}")
            print("Valor de la función en la aproximación inicial", logverosimilitud_2(x0))
            exito += 1
            a_prom = res.x[0] + a_prom
            b_prom = res.x[1] + b_prom
            beta_prom = res.x[2] + beta_prom
            print(x0)
            if (logverosimilitud_2(x0)== -res.fun):
                sin_cambios += 1
        else:
            print("La optimización no fue exitosa.")
            print("Mensaje:", res.message)
            fracaso += 1

print("\n Después de ", Iteraciones, "iteraciones, hubo ", exito, "éxitos, y ", fracaso, "fracasos")
print("Porcentaje de éxito: ", exito*100/Iteraciones, "%")
print("Porcentaje de fracaso: ", fracaso*100/Iteraciones, "%")
print("En ", sin_cambios, "iteraciones no se realizó un cambio de parámetros")
print("Valor promedio de a:", a_prom/exito)
print("Valor promedio de b:", b_prom/exito)
print("Valor promedio de beta:", beta_prom/exito)